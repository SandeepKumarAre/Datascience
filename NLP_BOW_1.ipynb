{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 'This pasta is very tasty and affordable'\n",
    "r2 = 'This pasta is not tasty and is a affordable'\n",
    "r3 = 'This pasta os delicious and cheap'\n",
    "r4 = 'Pasta is tasty and pasta tastes good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = 'Beans. I was trying to explain to somebody as we were flying in, that’s corn. That’s beans. And they were very impressed at my agricultural knowledge. Please give it up for Amaury once again for that outstanding introduction. I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we’re lucky to have him, your Senator, Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, and somehow he has not aged and I have. And it’s great to see you, Governor. I want to thank President Killeen and everybody at the U of I System for making it possible for me to be here today. And I am deeply honored at the Paul Douglas Award that is being given to me. He is somebody who set the path for so much outstanding public service here in Illinois. Now, I want to start by addressing the elephant in the room. I know people are still wondering why I didn’t speak at the commencement.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beans. I was trying to explain to somebody as we were flying in, that’s corn. That’s beans. And they were very impressed at my agricultural knowledge. Please give it up for Amaury once again for that outstanding introduction. I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we’re lucky to have him, your Senator, Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, and somehow he has not aged and I have. And it’s great to see you, Governor. I want to thank President Killeen and everybody at the U of I System for making it possible for me to be here today. And I am deeply honored at the Paul Douglas Award that is being given to me. He is somebody who set the path for so much outstanding public service here in Illinois. Now, I want to start by addressing the elephant in the room. I know people are still wondering why I didn’t speak at the commencement.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nltk.sent_tokenize(Text)\n",
    "#token_1 # Here we did with Tokenization...\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = dataset[i].lower()\n",
    "   \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beans.',\n",
       " 'i was trying to explain to somebody as we were flying in, that’s corn.',\n",
       " 'that’s beans.',\n",
       " 'and they were very impressed at my agricultural knowledge.',\n",
       " 'please give it up for amaury once again for that outstanding introduction.',\n",
       " 'i have a bunch of good friends here today, including somebody who i served with, who is one of the finest senators in the country, and we’re lucky to have him, your senator, dick durbin is here.',\n",
       " 'i also noticed, by the way, former governor edgar here, who i haven’t seen in a long time, and somehow he has not aged and i have.',\n",
       " 'and it’s great to see you, governor.',\n",
       " 'i want to thank president killeen and everybody at the u of i system for making it possible for me to be here today.',\n",
       " 'and i am deeply honored at the paul douglas award that is being given to me.',\n",
       " 'he is somebody who set the path for so much outstanding public service here in illinois.',\n",
       " 'now, i want to start by addressing the elephant in the room.',\n",
       " 'i know people are still wondering why i didn’t speak at the commencement.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We declare a dictionary to hold our bag of words.\n",
    "# Next we tokenize each sentence to words.\n",
    "# Now for each word in sentence, we check if the word exists in our dictionary.\n",
    "# If it does, then we increment its count by 1. If it doesn’t, we add it to our dictionary and set its count as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {} \n",
    "for data in dataset: \n",
    "    words = nltk.word_tokenize(data) \n",
    "    for word in words: \n",
    "        if word not in word2count.keys(): \n",
    "            word2count[word] = 1\n",
    "        else: \n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beans': 2,\n",
       " '.': 13,\n",
       " 'i': 12,\n",
       " 'was': 1,\n",
       " 'trying': 1,\n",
       " 'to': 8,\n",
       " 'explain': 1,\n",
       " 'somebody': 3,\n",
       " 'as': 1,\n",
       " 'we': 2,\n",
       " 'were': 2,\n",
       " 'flying': 1,\n",
       " 'in': 5,\n",
       " ',': 12,\n",
       " 'that': 4,\n",
       " '’': 6,\n",
       " 's': 3,\n",
       " 'corn': 1,\n",
       " 'and': 7,\n",
       " 'they': 1,\n",
       " 'very': 1,\n",
       " 'impressed': 1,\n",
       " 'at': 4,\n",
       " 'my': 1,\n",
       " 'agricultural': 1,\n",
       " 'knowledge': 1,\n",
       " 'please': 1,\n",
       " 'give': 1,\n",
       " 'it': 3,\n",
       " 'up': 1,\n",
       " 'for': 5,\n",
       " 'amaury': 1,\n",
       " 'once': 1,\n",
       " 'again': 1,\n",
       " 'outstanding': 2,\n",
       " 'introduction': 1,\n",
       " 'have': 3,\n",
       " 'a': 2,\n",
       " 'bunch': 1,\n",
       " 'of': 3,\n",
       " 'good': 1,\n",
       " 'friends': 1,\n",
       " 'here': 5,\n",
       " 'today': 2,\n",
       " 'including': 1,\n",
       " 'who': 4,\n",
       " 'served': 1,\n",
       " 'with': 1,\n",
       " 'is': 4,\n",
       " 'one': 1,\n",
       " 'the': 9,\n",
       " 'finest': 1,\n",
       " 'senators': 1,\n",
       " 'country': 1,\n",
       " 're': 1,\n",
       " 'lucky': 1,\n",
       " 'him': 1,\n",
       " 'your': 1,\n",
       " 'senator': 1,\n",
       " 'dick': 1,\n",
       " 'durbin': 1,\n",
       " 'also': 1,\n",
       " 'noticed': 1,\n",
       " 'by': 2,\n",
       " 'way': 1,\n",
       " 'former': 1,\n",
       " 'governor': 2,\n",
       " 'edgar': 1,\n",
       " 'haven': 1,\n",
       " 't': 2,\n",
       " 'seen': 1,\n",
       " 'long': 1,\n",
       " 'time': 1,\n",
       " 'somehow': 1,\n",
       " 'he': 2,\n",
       " 'has': 1,\n",
       " 'not': 1,\n",
       " 'aged': 1,\n",
       " 'great': 1,\n",
       " 'see': 1,\n",
       " 'you': 1,\n",
       " 'want': 2,\n",
       " 'thank': 1,\n",
       " 'president': 1,\n",
       " 'killeen': 1,\n",
       " 'everybody': 1,\n",
       " 'u': 1,\n",
       " 'system': 1,\n",
       " 'making': 1,\n",
       " 'possible': 1,\n",
       " 'me': 2,\n",
       " 'be': 1,\n",
       " 'am': 1,\n",
       " 'deeply': 1,\n",
       " 'honored': 1,\n",
       " 'paul': 1,\n",
       " 'douglas': 1,\n",
       " 'award': 1,\n",
       " 'being': 1,\n",
       " 'given': 1,\n",
       " 'set': 1,\n",
       " 'path': 1,\n",
       " 'so': 1,\n",
       " 'much': 1,\n",
       " 'public': 1,\n",
       " 'service': 1,\n",
       " 'illinois': 1,\n",
       " 'now': 1,\n",
       " 'start': 1,\n",
       " 'addressing': 1,\n",
       " 'elephant': 1,\n",
       " 'room': 1,\n",
       " 'know': 1,\n",
       " 'people': 1,\n",
       " 'are': 1,\n",
       " 'still': 1,\n",
       " 'wondering': 1,\n",
       " 'why': 1,\n",
       " 'didn': 1,\n",
       " 'speak': 1,\n",
       " 'commencement': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'know',\n",
       " 'people',\n",
       " 'are',\n",
       " 'still',\n",
       " 'wondering',\n",
       " 'why',\n",
       " 'i',\n",
       " 'didn',\n",
       " '’',\n",
       " 't',\n",
       " 'speak',\n",
       " 'at',\n",
       " 'the',\n",
       " 'commencement',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq \n",
    "freq_words = heapq.nlargest(100, word2count, key=word2count.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'i',\n",
       " ',',\n",
       " 'the',\n",
       " 'to',\n",
       " 'and',\n",
       " '’',\n",
       " 'in',\n",
       " 'for',\n",
       " 'here',\n",
       " 'that',\n",
       " 'at',\n",
       " 'who',\n",
       " 'is',\n",
       " 'somebody',\n",
       " 's',\n",
       " 'it',\n",
       " 'have',\n",
       " 'of',\n",
       " 'beans',\n",
       " 'we',\n",
       " 'were',\n",
       " 'outstanding',\n",
       " 'a',\n",
       " 'today',\n",
       " 'by',\n",
       " 'governor',\n",
       " 't',\n",
       " 'he',\n",
       " 'want',\n",
       " 'me',\n",
       " 'was',\n",
       " 'trying',\n",
       " 'explain',\n",
       " 'as',\n",
       " 'flying',\n",
       " 'corn',\n",
       " 'they',\n",
       " 'very',\n",
       " 'impressed',\n",
       " 'my',\n",
       " 'agricultural',\n",
       " 'knowledge',\n",
       " 'please',\n",
       " 'give',\n",
       " 'up',\n",
       " 'amaury',\n",
       " 'once',\n",
       " 'again',\n",
       " 'introduction',\n",
       " 'bunch',\n",
       " 'good',\n",
       " 'friends',\n",
       " 'including',\n",
       " 'served',\n",
       " 'with',\n",
       " 'one',\n",
       " 'finest',\n",
       " 'senators',\n",
       " 'country',\n",
       " 're',\n",
       " 'lucky',\n",
       " 'him',\n",
       " 'your',\n",
       " 'senator',\n",
       " 'dick',\n",
       " 'durbin',\n",
       " 'also',\n",
       " 'noticed',\n",
       " 'way',\n",
       " 'former',\n",
       " 'edgar',\n",
       " 'haven',\n",
       " 'seen',\n",
       " 'long',\n",
       " 'time',\n",
       " 'somehow',\n",
       " 'has',\n",
       " 'not',\n",
       " 'aged',\n",
       " 'great',\n",
       " 'see',\n",
       " 'you',\n",
       " 'thank',\n",
       " 'president',\n",
       " 'killeen',\n",
       " 'everybody',\n",
       " 'u',\n",
       " 'system',\n",
       " 'making',\n",
       " 'possible',\n",
       " 'be',\n",
       " 'am',\n",
       " 'deeply',\n",
       " 'honored',\n",
       " 'paul',\n",
       " 'douglas',\n",
       " 'award',\n",
       " 'being',\n",
       " 'given']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] \n",
    "for data in dataset: \n",
    "    vector = [] \n",
    "    for word in freq_words: \n",
    "        if word in nltk.word_tokenize(data): \n",
    "            vector.append(1) \n",
    "        else: \n",
    "            vector.append(0) \n",
    "    X.append(vector) \n",
    "X = np.asarray(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # Creating vector with words and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in freq_words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stemswords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". : .\n",
      ", : ,\n",
      "’ : ’\n",
      "somebody : somebodi\n",
      "beans : bean\n",
      "outstanding : outstand\n",
      "today : today\n",
      "governor : governor\n",
      "want : want\n",
      "trying : tri\n",
      "explain : explain\n",
      "flying : fli\n",
      "corn : corn\n",
      "impressed : impress\n",
      "agricultural : agricultur\n",
      "knowledge : knowledg\n",
      "please : pleas\n",
      "give : give\n",
      "amaury : amauri\n",
      "introduction : introduct\n",
      "bunch : bunch\n",
      "good : good\n",
      "friends : friend\n",
      "including : includ\n",
      "served : serv\n",
      "one : one\n",
      "finest : finest\n",
      "senators : senat\n",
      "country : countri\n",
      "lucky : lucki\n",
      "senator : senat\n",
      "dick : dick\n",
      "durbin : durbin\n",
      "also : also\n",
      "noticed : notic\n",
      "way : way\n",
      "former : former\n",
      "edgar : edgar\n",
      "seen : seen\n",
      "long : long\n",
      "time : time\n",
      "somehow : somehow\n",
      "aged : age\n",
      "great : great\n",
      "see : see\n",
      "thank : thank\n",
      "president : presid\n",
      "killeen : killeen\n",
      "everybody : everybodi\n",
      "u : u\n",
      "system : system\n",
      "making : make\n",
      "possible : possibl\n",
      "deeply : deepli\n",
      "honored : honor\n",
      "paul : paul\n",
      "douglas : dougla\n",
      "award : award\n",
      "given : given\n"
     ]
    }
   ],
   "source": [
    "for w in filtered_sent:\n",
    "    print(w ,':',ps.stem(w))\n",
    "    stemswords.append(ps.stem(w))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['given',\n",
       " '.',\n",
       " ',',\n",
       " '’',\n",
       " 'somebodi',\n",
       " 'bean',\n",
       " 'outstand',\n",
       " 'today',\n",
       " 'governor',\n",
       " 'want',\n",
       " 'tri',\n",
       " 'explain',\n",
       " 'fli',\n",
       " 'corn',\n",
       " 'impress',\n",
       " 'agricultur',\n",
       " 'knowledg',\n",
       " 'pleas',\n",
       " 'give',\n",
       " 'amauri',\n",
       " 'introduct',\n",
       " 'bunch',\n",
       " 'good',\n",
       " 'friend',\n",
       " 'includ',\n",
       " 'serv',\n",
       " 'one',\n",
       " 'finest',\n",
       " 'senat',\n",
       " 'countri',\n",
       " 'lucki',\n",
       " 'senat',\n",
       " 'dick',\n",
       " 'durbin',\n",
       " 'also',\n",
       " 'notic',\n",
       " 'way',\n",
       " 'former',\n",
       " 'edgar',\n",
       " 'seen',\n",
       " 'long',\n",
       " 'time',\n",
       " 'somehow',\n",
       " 'age',\n",
       " 'great',\n",
       " 'see',\n",
       " 'thank',\n",
       " 'presid',\n",
       " 'killeen',\n",
       " 'everybodi',\n",
       " 'u',\n",
       " 'system',\n",
       " 'make',\n",
       " 'possibl',\n",
       " 'deepli',\n",
       " 'honor',\n",
       " 'paul',\n",
       " 'dougla',\n",
       " 'award',\n",
       " 'given']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemit  = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given : given\n",
      ". : .\n",
      ", : ,\n",
      "’ : ’\n",
      "somebodi : somebodi\n",
      "bean : bean\n",
      "outstand : outstand\n",
      "today : today\n",
      "governor : governor\n",
      "want : want\n",
      "tri : tri\n",
      "explain : explain\n",
      "fli : fli\n",
      "corn : corn\n",
      "impress : impress\n",
      "agricultur : agricultur\n",
      "knowledg : knowledg\n",
      "pleas : plea\n",
      "give : give\n",
      "amauri : amauri\n",
      "introduct : introduct\n",
      "bunch : bunch\n",
      "good : good\n",
      "friend : friend\n",
      "includ : includ\n",
      "serv : serv\n",
      "one : one\n",
      "finest : finest\n",
      "senat : senat\n",
      "countri : countri\n",
      "lucki : lucki\n",
      "senat : senat\n",
      "dick : dick\n",
      "durbin : durbin\n",
      "also : also\n",
      "notic : notic\n",
      "way : way\n",
      "former : former\n",
      "edgar : edgar\n",
      "seen : seen\n",
      "long : long\n",
      "time : time\n",
      "somehow : somehow\n",
      "age : age\n",
      "great : great\n",
      "see : see\n",
      "thank : thank\n",
      "presid : presid\n",
      "killeen : killeen\n",
      "everybodi : everybodi\n",
      "u : u\n",
      "system : system\n",
      "make : make\n",
      "possibl : possibl\n",
      "deepli : deepli\n",
      "honor : honor\n",
      "paul : paul\n",
      "dougla : dougla\n",
      "award : award\n",
      "given : given\n",
      "corpora   : corpora \n"
     ]
    }
   ],
   "source": [
    "for lm in stemswords:\n",
    "    print(lm,':',lemit.lemmatize(lm))\n",
    "\n",
    "print('corpora   :',lemit.lemmatize('corpora ',pos=\"a\")   )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
